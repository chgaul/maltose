{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import ase.io\n",
    "import torch\n",
    "import schnetpack\n",
    "\n",
    "from schnetpack_custom.atoms import MultitaskAtomsData\n",
    "import data.paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_on_xyz(model, xyzfile):\n",
    "    return model.forward(\n",
    "        schnetpack.data.loader._collate_aseatoms([\n",
    "            schnetpack.data.atoms.torchify_dict(\n",
    "                schnetpack.data.atoms._convert_atoms(\n",
    "                    ase.io.read(xyzfile)\n",
    "                )\n",
    "            )\n",
    "        ])\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_dir(model_name):\n",
    "    return os.path.join('/home/cgaul/MaLTOSe2020/schnetpack_exps/models/', model_name, 'best_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For example, load the multiask_model:\n",
    "model_name = 'multitask_model'\n",
    "model = torch.load(model_dir(model_name), map_location=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate model on unified test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# QM9\n",
    "dataset_qm9 = MultitaskAtomsData(\n",
    "    schnetpack.datasets.QM9(data.paths.QM9.db, load_only=['homo', 'lumo', 'gap']), [\n",
    "        ('HOMO-B3LYP', 'homo'),\n",
    "        ('LUMO-B3LYP', 'lumo'),\n",
    "        ('Gap-B3LYP', 'gap')],\n",
    "    validity_column=False)\n",
    "_, _, test_qm9 = schnetpack.data.partitioning.train_test_split(\n",
    "    data=dataset_qm9, split_file=data.paths.QM9.split_v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_file = data.paths.Alchemy.split_v2\n",
    "dataset = MultitaskAtomsData(\n",
    "    schnetpack.data.atoms.AtomsData(data.paths.Alchemy.db, load_only=['homo', 'lumo', 'gap']), [\n",
    "        ('HOMO-B3LYP', 'homo'),\n",
    "        ('LUMO-B3LYP', 'lumo'),\n",
    "        ('Gap-B3LYP', 'gap')],\n",
    "    validity_column=False)\n",
    "_, _, test_alchemy = schnetpack.data.partitioning.train_test_split(\n",
    "    data=dataset, split_file=split_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_file = data.paths.OE62.split_v2\n",
    "dataset = MultitaskAtomsData(\n",
    "    schnetpack.data.atoms.AtomsData(data.paths.OE62.db), [\n",
    "        ('HOMO-PBE0', 'homo PBE0_vacuum'),\n",
    "        ('LUMO-PBE0', 'lumo PBE0_vacuum'),\n",
    "        ('Gap-PBE0', 'gap PBE0_vacuum')],\n",
    "    validity_column=False)\n",
    "_, _, test_oe62 = schnetpack.data.partitioning.train_test_split(\n",
    "    data=dataset, split_file=split_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hopv_split_file = data.paths.HOPV.split_v2\n",
    "dataset_hopv = MultitaskAtomsData(\n",
    "    schnetpack.data.atoms.AtomsData(data.paths.HOPV.db), [\n",
    "        ('HOMO-B3LYP', 'HOMO B3LYP/def2-SVP'),\n",
    "        ('LUMO-B3LYP', 'LUMO B3LYP/def2-SVP'),\n",
    "        ('Gap-B3LYP', 'Gap B3LYP/def2-SVP'),\n",
    "        ('HOMO-PBE0', 'HOMO PBE0/def2-SVP'),\n",
    "        ('LUMO-PBE0', 'LUMO PBE0/def2-SVP'),\n",
    "        ('Gap-PBE0', 'Gap PBE0/def2-SVP')],\n",
    "    validity_column=False)\n",
    "_, _, test_hopv = schnetpack.data.partitioning.train_test_split(\n",
    "    data=dataset_hopv, split_file=hopv_split_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_file = data.paths.TABS.split_v2\n",
    "dataset = MultitaskAtomsData(\n",
    "    schnetpack.data.atoms.AtomsData(data.paths.TABS.db), [\n",
    "        ('HOMO-B3LYP', 'homo'),\n",
    "        ('LUMO-B3LYP', 'lumo'),\n",
    "        ('Gap-B3LYP', 'gap')],\n",
    "    validity_column=False)\n",
    "_, _, test_tabs = schnetpack.data.partitioning.train_test_split(\n",
    "    data=dataset, split_file=split_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = {\n",
    "    \"QM9_test\": test_qm9,\n",
    "    \"Alchemy_test\": test_alchemy,\n",
    "    \"OE62_test\": test_oe62,\n",
    "    \"HOPV_test\": test_hopv,\n",
    "    \"TABS\": test_tabs,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_available_properties(model):\n",
    "    try: # for Set2Set output module\n",
    "         return [p for om in model.output_modules for p in om.properties]\n",
    "    except: # for Atomwise output module\n",
    "        return [om.property for om in model.output_modules]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_unified(model, dataset_name, n_points=None, seed=None):\n",
    "    dataset = datasets[dataset_name]\n",
    "    batch_size = 10\n",
    "    \n",
    "    gen = torch.Generator()\n",
    "    if seed:\n",
    "        gen.manual_seed(seed)\n",
    "    else:\n",
    "        gen.seed()\n",
    "    sampler = torch.utils.data.RandomSampler(dataset, replacement=False, generator=gen)\n",
    "    batch_sampler = torch.utils.data.BatchSampler(sampler, batch_size, drop_last=False)\n",
    "\n",
    "    ret = {\n",
    "        'tgt': {p: np.array([]) for p in dataset.available_properties},\n",
    "        'est': {p: np.array([]) for p in get_available_properties(model=model)},\n",
    "    }\n",
    "    test_loader = schnetpack.data.loader.AtomsLoader(dataset, batch_sampler=batch_sampler)\n",
    "    for i, b in enumerate(test_loader):\n",
    "        for p in ret['tgt'].keys():\n",
    "            ret['tgt'][p] = np.append(ret['tgt'][p], b[p])\n",
    "        b = {k: v.to(device) for k, v in b.items()}\n",
    "        est = model(b)\n",
    "        for p in ret['est'].keys():\n",
    "            ret['est'][p] = np.append(ret['est'][p], est[p].detach().to('cpu').numpy())\n",
    "        if n_points is not None and (i+1) * batch_size >= n_points:\n",
    "            break\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_regular_data(n_points=100, seed=None):\n",
    "    return {\n",
    "        dataset_name: evaluate_unified(\n",
    "            model, dataset_name, n_points, seed=seed) for dataset_name in datasets.keys()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tgt_est = compute_regular_data(n_points=100, seed=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate model on data of Kuzmich2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_kuzmich(model):\n",
    "    ret = {}\n",
    "    df = pd.read_csv('../Data/Kuzmich2017/table1.csv')\n",
    "    mapping = {\n",
    "        'DTDfBTTDPP2': 'DTDfBT(TDPP)2',\n",
    "        '10_DBFI-MTT': 'DBFI-MTT',\n",
    "    }\n",
    "    ambiguous = ['M10']\n",
    "    for f in sorted(os.listdir('../Data/Kuzmich2017/fixed_xyz/')):\n",
    "        if f.endswith('.xyz'):\n",
    "            id = f[3:-13]\n",
    "            if id in mapping:\n",
    "                id = mapping[id]\n",
    "            if id in ambiguous:\n",
    "                print('id: {} ambiguous'.format(f[3:-13]))\n",
    "                continue\n",
    "            lb = f[3:-13]\n",
    "            xyzfile = os.path.join('../Data/Kuzmich2017/fixed_xyz/', f)\n",
    "            pred = predict_on_xyz(model, xyzfile)\n",
    "            est = {k: float(v) for k, v in pred.items()}\n",
    "            tgt = {\n",
    "                'LUMO-B3LYP': float(df[df['Acceptorâ€™s Label']==id]['LUMO (eV)'])\n",
    "            }\n",
    "            ret[lb] = {\n",
    "                'tgt': tgt,\n",
    "                'est': est,\n",
    "            }\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tgt_est_kuzmich = evaluate_kuzmich(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "est_properties = get_available_properties(model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Kuzmich2017 data alone:\n",
    "qe = 'LUMO-B3LYP' if 'LUMO-B3LYP' in est_properties else 'LUMO-PBE0'\n",
    "qt = 'LUMO-B3LYP'\n",
    "x = [v['tgt'][qt] for v in tgt_est_kuzmich.values()]\n",
    "y = [v['est'][qe] for v in tgt_est_kuzmich.values()]\n",
    "plt.scatter(x, y)\n",
    "plt.axline((np.mean(x), np.mean(x)), slope=1)\n",
    "plt.xlabel('{} target (eV)'.format(qt))\n",
    "plt.ylabel('{} estimate (eV)'.format(qe))\n",
    "plt.title(model_name)\n",
    "plt.show()\n",
    "dev = np.array(x) - np.array(y)\n",
    "print('MAE={:.2f}(eV), RMSE={:.2f}eV'.format(\n",
    "    np.mean(np.abs(dev)),\n",
    "    np.sqrt(np.mean(np.square(dev)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bring data into the regular format:\n",
    "def add_kuzmich(tgt_est, seed=None):\n",
    "    random_state = np.random.RandomState(seed=seed)\n",
    "    tgt_est_kuzmich = evaluate_kuzmich(model)\n",
    "    # Sort by keys:\n",
    "    k_data = sorted(list(tgt_est_kuzmich.items()))\n",
    "    # Shuffle order\n",
    "    random_state.shuffle(k_data)\n",
    "    # Drop keys:\n",
    "    k_data = [v for _, v in k_data]\n",
    "    ret = {\n",
    "            'tgt': {p: np.array([]) for p in k_data[0]['tgt'].keys()},\n",
    "            'est': {p: np.array([]) for p in k_data[0]['est'].keys()},\n",
    "        }\n",
    "    for kd in k_data:\n",
    "        for k in ret['tgt'].keys():\n",
    "            ret['tgt'][k] = np.append(ret['tgt'][k], [kd['tgt'][k]])\n",
    "        for k in ret['est'].keys():\n",
    "            ret['est'][k] = np.append(ret['est'][k], [kd['est'][k]])\n",
    "    tgt_est['Kuzmich2017'] = ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_kuzmich(tgt_est, seed=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Streamlined evaluation and plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOMSEED = 26463461"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'multitask_model_v08'\n",
    "model = torch.load(model_dir(model_name), map_location=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'multitask_model_v06_prelim'\n",
    "model = torch.load(model_dir(model_name), map_location=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'multitask_model_only_b3lyp'\n",
    "model = torch.load(model_dir(model_name), map_location=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'multitask_model'\n",
    "model = torch.load(model_dir(model_name), map_location=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'multitask_model_v05'\n",
    "model = torch.load(model_dir(model_name), map_location=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'multitask_model_only_pbe0'\n",
    "model = torch.load(model_dir(model_name), map_location=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "est_properties = get_available_properties(model=model)\n",
    "tgt_est = compute_regular_data(n_points=200, seed=RANDOMSEED)\n",
    "add_kuzmich(tgt_est, seed=RANDOMSEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse and plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a fixed color code for each test set\n",
    "for k, color in {\n",
    "    'QM9_test': 'orange',\n",
    "    'Alchemy_test': 'red',\n",
    "    'OE62_test': 'purple',\n",
    "    'HOPV_test': 'blue',\n",
    "    'TABS': 'green',\n",
    "    'Kuzmich2017': 'black'\n",
    "}.items():\n",
    "    if k in tgt_est:\n",
    "        tgt_est[k]['color'] = color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "properties = ['HOMO', 'LUMO', 'Gap']\n",
    "theories = ['B3LYP', 'PBE0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_plot(tgt_est, qt_tgt, qt_est, n_points=-1, skiptests=[]):\n",
    "    plot_empty = True\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    plotname = '{}-{}'.format(model_name, qt_tgt);\n",
    "    if qt_est != qt_tgt:\n",
    "        plotname += '-cross'\n",
    "    for dataset_name, te in tgt_est.items():\n",
    "        try:\n",
    "            x = te['tgt'][qt_tgt]\n",
    "            y = te['est'][qt_est]\n",
    "        except:\n",
    "            continue\n",
    "        if dataset_name in skiptests:\n",
    "            # Add a tag, but only if skipped due to skiptests: \n",
    "            plotname = '{}-skip{}'.format(plotname, dataset_name)\n",
    "            continue\n",
    "        dev = np.array(x) - np.array(y)\n",
    "        mae = np.mean(np.abs(dev))\n",
    "        rmse = np.sqrt(np.mean(np.square(dev)))\n",
    "        print('{}: MAE={:.2f}(eV), RMSE={:.2f}eV'.format(dataset_name, mae, rmse))\n",
    "        plt.scatter(x[:n_points], y[:n_points], color=te['color'], label='{dataset} (MAE={mae:.2f}eV)'.format(\n",
    "            dataset=dataset_name, mae=mae))\n",
    "        plt.axline((np.mean(x), np.mean(x)), slope=1)\n",
    "        plt.xlabel('{} target (eV)'.format(qt_tgt))\n",
    "        plt.ylabel('{} estimate (eV)'.format(qt_est))\n",
    "        plot_empty = False\n",
    "    if plot_empty:\n",
    "        print(\"{}/{} empty for {}.\".format(qt_tgt, qt_est, model_name))\n",
    "    else:\n",
    "        plt.title(model_name)\n",
    "        plt.grid()\n",
    "        plt.legend()\n",
    "        plt.savefig('{}.png'.format(plotname), dpi=200)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target-estimate plots for each property and theory (diagonal and cross)\n",
    "n_points = 25\n",
    "for skiptests in [[], ['TABS']]:\n",
    "    for a in properties:\n",
    "        for t in theories:\n",
    "            assert len(theories)==2\n",
    "            t_cross = [th for th in theories if th != t][0]\n",
    "            q = a + '-' + t\n",
    "            q_cross = a + '-' + t_cross\n",
    "            plt.rcParams.update({'axes.facecolor': 'lightgray'})\n",
    "            make_plot(tgt_est, q, q_cross, n_points=n_points, skiptests=skiptests)\n",
    "            plt.rcParams.update({'axes.facecolor': 'white'})\n",
    "            make_plot(tgt_est, q, q, n_points=n_points, skiptests=skiptests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "schnetpack_conda",
   "language": "python",
   "name": "schnetpack_conda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
