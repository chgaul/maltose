{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multitask Model trained on the Unified DB\n",
    "- The four datasets QM9, Alchemy, OE62, and HOPV, with the unified split (split v2) are used.\n",
    "- Two sets of molecular energies are trained: (HOMO, LUMO, gap) x (B3LYP, PBE0)\n",
    "- The network has the Set2Set + molecule-level output module with six outputs. Otherwise, the architecture is the same as qm9_hopv_model_v13."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import torch\n",
    "from torch.optim import Adam\n",
    "import os\n",
    "import schnetpack as spk\n",
    "import schnetpack.atomistic.model\n",
    "from schnetpack.data.atoms import AtomsData, ConcatAtomsData\n",
    "from schnetpack.train import Trainer, CSVHook, ReduceLROnPlateauHook\n",
    "from schnetpack.train.metrics import MeanAbsoluteError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from maltose.output_modules import Set2Set\n",
    "from maltose.atoms import MultitaskAtomsData\n",
    "from maltose.loss import build_gated_mse_loss\n",
    "from maltose.metrics import MultitaskMetricWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_base_dir = '../models'\n",
    "data_base_dir = '../data'\n",
    "device = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=os.environ.get(\"LOGLEVEL\", \"INFO\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic settings\n",
    "model_dir = os.path.join(model_base_dir, \"multitask_model_v01\")\n",
    "if not os.path.exists(model_dir):\n",
    "    print(\"Create model directory {}\".format(model_dir))\n",
    "    os.makedirs(model_dir)\n",
    "else:\n",
    "    print(\"{} exists:\".format(model_dir))\n",
    "    for file in os.listdir(model_dir):\n",
    "        print(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "properties = ['HOMO-B3LYP', 'LUMO-B3LYP', 'Gap-B3LYP', 'HOMO-PBE0', 'LUMO-PBE0', 'Gap-PBE0']\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info(\"get the datasets\")\n",
    "train_sets, val_sets, test_sets = [], [], []\n",
    "for dataset_name, mapping in [\n",
    "    ('qm9', [\n",
    "        ('HOMO-B3LYP', 'homo'), ('LUMO-B3LYP', 'lumo'), ('Gap-B3LYP', 'gap'), \n",
    "        ('HOMO-PBE0', None), ('LUMO-PBE0', None), ('Gap-PBE0', None)]),\n",
    "    ('alchemy', [\n",
    "        ('HOMO-B3LYP', 'homo'), ('LUMO-B3LYP', 'lumo'), ('Gap-B3LYP', 'gap'), \n",
    "        ('HOMO-PBE0', None), ('LUMO-PBE0', None), ('Gap-PBE0', None)]),\n",
    "    ('oe62', [\n",
    "        ('HOMO-B3LYP', None), ('LUMO-B3LYP', None), ('Gap-B3LYP', None), \n",
    "        ('HOMO-PBE0', 'homo PBE0_vacuum'), ('LUMO-PBE0', 'lumo PBE0_vacuum'), ('Gap-PBE0', 'gap PBE0_vacuum')]),\n",
    "    ('hopv', [\n",
    "        ('HOMO-B3LYP', 'HOMO B3LYP/def2-SVP'), ('LUMO-B3LYP', 'LUMO B3LYP/def2-SVP'), ('Gap-B3LYP', 'Gap B3LYP/def2-SVP'),\n",
    "        ('HOMO-PBE0', 'HOMO PBE0/def2-SVP'), ('LUMO-PBE0', 'LUMO PBE0/def2-SVP'), ('Gap-PBE0', 'Gap PBE0/def2-SVP')])\n",
    "    ]:\n",
    "    dataset_file = os.path.join(data_base_dir, dataset_name, 'data.db')\n",
    "    dataset = AtomsData(dataset_file, load_only=properties)\n",
    "    split_file = os.path.join(data_base_dir, dataset_name, 'split_v2.npz')\n",
    "    if not os.path.exists(split_file):\n",
    "        print(split_file, 'does not exist!')\n",
    "        print('Please run scripts/primary_data/unified_split.py first!')\n",
    "    train, val, test = spk.data.partitioning.train_test_split(\n",
    "        data=dataset, split_file=split_file)\n",
    "    train_sets.append(MultitaskAtomsData(train, mapping))\n",
    "    val_sets.append(MultitaskAtomsData(val, mapping))\n",
    "    test_sets.append(MultitaskAtomsData(test, mapping))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = ConcatAtomsData(train_sets)\n",
    "val = ConcatAtomsData(val_sets)\n",
    "test = ConcatAtomsData(test_sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = spk.AtomsLoader(train, batch_size=batch_size, shuffle=True)\n",
    "val_loader = spk.AtomsLoader(val, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train), len(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HOMO-B3LYP (8588 items): mean=-6.34, std=0.69\n",
      "LUMO-B3LYP (8588 items): mean=0.19, std=1.29\n",
      " Gap-B3LYP (8588 items): mean=6.53, std=1.52\n",
      " HOMO-PBE0 (1640 items): mean=-6.50, std=0.73\n",
      " LUMO-PBE0 (1640 items): mean=-1.57, std=0.92\n",
      "  Gap-PBE0 (1640 items): mean=4.93, std=1.19\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "def measure_mean_std(n_batches, batch_size):    \n",
    "    loader = spk.AtomsLoader(train, batch_size=batch_size, shuffle=True)\n",
    "    valids = {p: [] for p in properties}\n",
    "    for i, b in enumerate(loader):\n",
    "        for p in properties:\n",
    "            data = np.array(b[p])\n",
    "            validity = data[:, 0] > 0\n",
    "            valids[p].append(data[:, 1][validity])\n",
    "        print(len(valids[p]), end='\\r')\n",
    "        if i==n_batches: break\n",
    "    for p in properties:\n",
    "        arr = np.concatenate(valids[p])\n",
    "        print('{:>10} ({} items): mean={:.2f}, std={:.2f}'.format(p, len(arr), np.mean(arr), np.std(arr)))\n",
    "measure_mean_std(100, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precomputed statistics\n",
    "meanstensor = torch.tensor([-6.35, 0.17, 6.52, -6.48, -1.56, 4.92])\n",
    "stddevstensor = torch.tensor([0.71, 1.28, 1.51, 0.71, 0.91, 1.17])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model build\n",
    "logging.info(\"build model\")\n",
    "representation = spk.SchNet(n_interactions=6)\n",
    "output_modules = [\n",
    "    Set2Set(\n",
    "        n_in=representation.n_atom_basis,\n",
    "        processing_steps=3,\n",
    "        m_net_layers=2,\n",
    "        m_net_neurons=32,\n",
    "        properties=properties,\n",
    "        means=meanstensor,\n",
    "        stddevs=stddevstensor,\n",
    "    )\n",
    "]\n",
    "model = schnetpack.AtomisticModel(representation, output_modules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build optimizer\n",
    "optimizer = Adam(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hooks\n",
    "logging.info(\"build trainer\")\n",
    "metrics = [MultitaskMetricWrapper(MeanAbsoluteError(p, p)) for p in properties]\n",
    "hooks = [\n",
    "    CSVHook(log_path=model_dir, metrics=metrics),\n",
    "    ReduceLROnPlateauHook(\n",
    "        optimizer,\n",
    "        min_lr=0.5e-6,\n",
    "        stop_after_min=True),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = build_gated_mse_loss(properties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run training\n",
    "trainer = Trainer(\n",
    "    model_dir,\n",
    "    model=model,\n",
    "    hooks=hooks,\n",
    "    loss_fn=loss,\n",
    "    optimizer=optimizer,\n",
    "    train_loader=train_loader,\n",
    "    validation_loader=val_loader,\n",
    "    keep_n_checkpoints=40,\n",
    "    checkpoint_interval=10,\n",
    ")\n",
    "logging.info(\"training\")\n",
    "trainer.train(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "maltose-pip",
   "language": "python",
   "name": "maltose-pip"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
