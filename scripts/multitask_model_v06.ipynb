{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multitask Model trained on the Unified DB\n",
    "- The two datasets with the smallest molecules are used (QM9, Alchemy), with the unified split (split v2).\n",
    "- Only the B3LYP targets are available: (HOMO, LUMO, gap) x (B3LYP)\n",
    "- The network has the Set2Set + molecule-level output module with three outputs. Otherwise, the architecture is the same as qm9_hopv_model_v13 and similar to multitask_model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import torch\n",
    "from torch.optim import Adam\n",
    "import os\n",
    "import schnetpack as spk\n",
    "import schnetpack.atomistic.model\n",
    "from schnetpack.data.atoms import AtomsData, ConcatAtomsData\n",
    "from schnetpack.train import Trainer, CSVHook, ReduceLROnPlateauHook\n",
    "from schnetpack.train.metrics import MeanAbsoluteError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../') # add parent dir ('schnetpack_exps') dir to path\n",
    "from utils import is_main\n",
    "import data.paths\n",
    "from schnetpack_custom.output_modules import Set2Set\n",
    "from schnetpack_custom.atoms import MultitaskAtomsData\n",
    "from schnetpack_custom.loss import build_gated_mse_loss\n",
    "from schnetpack_custom.metrics import MultitaskMetricWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=os.environ.get(\"LOGLEVEL\", \"INFO\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic settings\n",
    "model_dir = os.path.join(data.paths.model_dir, \"multitask_model_v06\")\n",
    "if not os.path.exists(model_dir):\n",
    "    print(\"Create model directory {}\".format(model_dir))\n",
    "    os.makedirs(model_dir)\n",
    "else:\n",
    "    print(\"{} exists:\".format(model_dir))\n",
    "    for file in os.listdir(model_dir):\n",
    "        print(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "properties = ['HOMO-B3LYP', 'LUMO-B3LYP', 'Gap-B3LYP']\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info(\"get the datasets\")\n",
    "train_sets, val_sets, test_sets = [], [], []\n",
    "for DS, mapping in [\n",
    "    (data.paths.QM9, [\n",
    "        ('HOMO-B3LYP', 'homo'), ('LUMO-B3LYP', 'lumo'), ('Gap-B3LYP', 'gap'), \n",
    "        ('HOMO-PBE0', None), ('LUMO-PBE0', None), ('Gap-PBE0', None)]),\n",
    "    (data.paths.Alchemy, [\n",
    "        ('HOMO-B3LYP', 'homo'), ('LUMO-B3LYP', 'lumo'), ('Gap-B3LYP', 'gap'), \n",
    "        ('HOMO-PBE0', None), ('LUMO-PBE0', None), ('Gap-PBE0', None)]),\n",
    "    ]:\n",
    "    dataset = AtomsData(DS.db, load_only=properties)\n",
    "    train, val, test = spk.data.partitioning.train_test_split(\n",
    "        data=dataset, split_file=DS.split_v2)\n",
    "    train_sets.append(MultitaskAtomsData(train, mapping))\n",
    "    val_sets.append(MultitaskAtomsData(val, mapping))\n",
    "    test_sets.append(MultitaskAtomsData(test, mapping))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = ConcatAtomsData(train_sets)\n",
    "val = ConcatAtomsData(val_sets)\n",
    "test = ConcatAtomsData(test_sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = spk.AtomsLoader(train, batch_size=batch_size, shuffle=True)\n",
    "val_loader = spk.AtomsLoader(val, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train), len(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_main(__name__, globals()):\n",
    "    import numpy as np\n",
    "    def measure_mean_std(n_batches, batch_size):    \n",
    "        loader = spk.AtomsLoader(train, batch_size=batch_size, shuffle=True)\n",
    "        valids = {p: [] for p in properties}\n",
    "        for i, b in enumerate(loader):\n",
    "            for p in properties:\n",
    "                data = np.array(b[p])\n",
    "                validity = data[:, 0] > 0\n",
    "                valids[p].append(data[:, 1][validity])\n",
    "            print(len(valids[p]), end='\\r')\n",
    "            if i==n_batches: break\n",
    "        for p in properties:\n",
    "            arr = np.concatenate(valids[p])\n",
    "            print('{:>10} ({} items): mean={:.2f}, std={:.2f}'.format(p, len(arr), np.mean(arr), np.std(arr)))\n",
    "    measure_mean_std(100, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precomputed statistics\n",
    "meanstensor = torch.tensor([-6.36, 0.24, 6.59])\n",
    "stddevstensor = torch.tensor([0.69, 1.25, 1.44])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model build\n",
    "logging.info(\"build model\")\n",
    "representation = spk.SchNet(n_interactions=6)\n",
    "output_modules = [\n",
    "    Set2Set(\n",
    "        n_in=representation.n_atom_basis,\n",
    "        processing_steps=3,\n",
    "        m_net_layers=2,\n",
    "        m_net_neurons=32,\n",
    "        properties=properties,\n",
    "        means=meanstensor,\n",
    "        stddevs=stddevstensor,\n",
    "    )\n",
    "]\n",
    "model = schnetpack.AtomisticModel(representation, output_modules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build optimizer\n",
    "optimizer = Adam(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hooks\n",
    "logging.info(\"build trainer\")\n",
    "metrics = [MultitaskMetricWrapper(MeanAbsoluteError(p, p)) for p in properties]\n",
    "hooks = [\n",
    "    CSVHook(log_path=model_dir, metrics=metrics),\n",
    "    ReduceLROnPlateauHook(\n",
    "        optimizer,\n",
    "        min_lr=0.5e-6,\n",
    "        stop_after_min=True),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = build_gated_mse_loss(properties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run training\n",
    "if is_main(__name__, globals()):\n",
    "    trainer = Trainer(\n",
    "        model_dir,\n",
    "        model=model,\n",
    "        hooks=hooks,\n",
    "        loss_fn=loss,\n",
    "        optimizer=optimizer,\n",
    "        train_loader=train_loader,\n",
    "        validation_loader=val_loader,\n",
    "        keep_n_checkpoints=40,\n",
    "        checkpoint_interval=10,\n",
    "    )\n",
    "    logging.info(\"training\")\n",
    "    trainer.train(device=\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "schnetpack-extd",
   "language": "python",
   "name": "schnetpack-extd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
